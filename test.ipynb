{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import random\n",
    "\n",
    "from IPython import display\n",
    "from skimage.draw import random_shapes, rectangle, polygon, circle\n",
    "\n",
    "tf.config.gpu.set_per_process_memory_growth(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_SIZE = 28\n",
    "IMAGE_COUNT = 600\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "NUM_EXAMPLES_TO_GENERATE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_mask(size=(448, 448), max_shapes=3, show_result=False):\n",
    "    image, labels = random_shapes(size, min_shapes=1, max_shapes=max_shapes,\n",
    "                             min_size=size[0]/4, allow_overlap=True, multichannel=False, shape='triangle')\n",
    "\n",
    "    masks = []\n",
    "    for i in range(0, len(labels)):\n",
    "        img= np.zeros(size, dtype=np.uint8)\n",
    "\n",
    "        if(labels[i][0] == 'rectangle'):\n",
    "            rr, cc = rectangle((labels[i][1][0][0], labels[i][1][1][0]), (labels[i][1][0][1], labels[i][1][1][1]),\n",
    "                       shape=img.shape)\n",
    "        if(labels[i][0] == 'circle'):\n",
    "            y = labels[i][1][0][1]- (labels[i][1][0][1] - labels[i][1][0][0]) / 2\n",
    "            x = labels[i][1][1][1]-(labels[i][1][1][1] - labels[i][1][1][0]) / 2\n",
    "            r = (labels[i][1][0][1] - labels[i][1][0][0]) / 2        \n",
    "            rr, cc = circle(y, x, r, shape=img.shape)\n",
    "        if(labels[i][0] == 'triangle'):\n",
    "            x = (labels[i][1][1][0], labels[i][1][1][1] - (labels[i][1][1][1] - labels[i][1][1][0]) / 2, labels[i][1][1][1], labels[i][1][1][0])\n",
    "            y = (labels[i][1][0][1], labels[i][1][0][0], labels[i][1][0][1], labels[i][1][0][1])\n",
    "            rr, cc = polygon(y, x, shape=img.shape)                \n",
    "\n",
    "        img[rr, cc] = 1\n",
    "        masks.append(img)\n",
    "        \n",
    "    if(show_result):\n",
    "        print(labels)\n",
    "        fig=plt.figure(figsize=(8, 8))\n",
    "        fig.add_subplot(1, len(labels)+1, 1)\n",
    "        plt.imshow(image)\n",
    "        for i in range(0, len(labels)):    \n",
    "            fig.add_subplot(1, len(labels)+1, i+2)\n",
    "            plt.imshow(masks[i], cmap=\"Greys\")\n",
    "        plt.show()\n",
    "    return image, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(raw_image):\n",
    "    t = tf.convert_to_tensor(raw_image, np.float32)\n",
    "    t = tf.reshape(t, (SHAPE_SIZE, SHAPE_SIZE, 1,))\n",
    "    t = (t - 127.5) / 127.5\n",
    "    return t\n",
    "\n",
    "def preprocess_mask(raw_mask):\n",
    "    t = tf.convert_to_tensor(raw_mask, np.float32)\n",
    "    #t = tf.dense(t, (784))\n",
    "    t = tf.reshape(t, (SHAPE_SIZE, SHAPE_SIZE, 1,))\n",
    "    t = (t - 127.5) / 127.5\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "for i in range(0, IMAGE_COUNT):\n",
    "    image, img_masks = generate_image_mask(size=(SHAPE_SIZE, SHAPE_SIZE), max_shapes=1)\n",
    "    images.append(preprocess_image(image))\n",
    "    masks.append(preprocess_mask(img_masks[0]))\n",
    "    if((i / IMAGE_COUNT * 100.0) % 10 == 0):\n",
    "        print(i)\n",
    "# Display a sample image\n",
    "plt.imshow(images[0][:, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "#plt.imshow(images[0][:, :] * 127.5 + 127.5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds = tf.data.Dataset.from_tensor_slices(images)\n",
    "msk_ds = tf.data.Dataset.from_tensor_slices(masks)\n",
    "img_msk_ds = tf.data.Dataset.zip((img_ds, msk_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "#ds = img_msk_ds.apply(\n",
    "#  tf.data.experimental.shuffle_and_repeat(buffer_size=IMAGE_COUNT))\n",
    "#ds = ds.batch(BATCH_SIZE)\n",
    "#ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "#ds\n",
    "\n",
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "ds = img_msk_ds.shuffle(buffer_size=IMAGE_COUNT)\n",
    "#ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(SHAPE_SIZE,SHAPE_SIZE,1,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    #model.add(layers.Reshape((28, 28, 256)))\n",
    "    #assert model.output_shape == (None, 28, 28, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    #assert model.output_shape == (None, 56, 56, 16)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    #assert model.output_shape == (None, 56, 56, 16)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    #assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    #assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    #model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    #assert model.output_shape == (None, 7, 7, 128)\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    #model.add(layers.LeakyReLU())\n",
    "\n",
    "    #model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    #assert model.output_shape == (None, 14, 14, 64)\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    \n",
    "    #model.add(layers.Dense(1))\n",
    "    #model.add(layers.Reshape((SHAPE_SIZE, SHAPE_SIZE, 1,)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    #assert model.output_shape == (None, 224, 224, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, SHAPE_SIZE, SHAPE_SIZE, 1])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image.shape)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image2 = generator(tf.reshape(tf.convert_to_tensor(images[0]), (1, 28, 28, 1)), training=False)\n",
    "print(generated_image2.shape)\n",
    "plt.imshow(generated_image2[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[SHAPE_SIZE, SHAPE_SIZE, 1]))\n",
    "    \n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))    \n",
    "    \n",
    "    #model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    #model.add(layers.Conv2D(1024, (5, 5), strides=(2, 2), padding='same'))\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    #model.add(layers.Dropout(0.3))        \n",
    "    \n",
    "    #model.add(layers.Conv2D(2048, (5, 5), strides=(2, 2), padding='same'))\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    #model.add(layers.Conv2D(4096, (5, 5), strides=(2, 2), padding='same'))\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    #model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "print(generated_image.shape)\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = SHAPE_SIZE\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "#seed = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, noise_dim, noise_dim, 1])\n",
    "seed = []\n",
    "seed_truth = []\n",
    "for i in range(0, NUM_EXAMPLES_TO_GENERATE):\n",
    "    img, truth = generate_image_mask(size=(SHAPE_SIZE, SHAPE_SIZE), max_shapes=1)\n",
    "    seed.append(preprocess_image(img))\n",
    "    seed_truth.append(preprocess_mask(truth))\n",
    "seed = tf.convert_to_tensor(seed)\n",
    "#print(seed_truth[0])\n",
    "#plt.imshow(seed_truth[0][:, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "#print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images, masks):\n",
    "    #noise = tf.random.normal([BATCH_SIZE, noise_dim, noise_dim, 1])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(masks, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch, mask_batch in dataset:\n",
    "            train_step(image_batch, mask_batch)\n",
    "\n",
    "        # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,\n",
    "                                 epoch + 1,\n",
    "                                 seed)\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    offset = 1\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 2, i+offset)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(4, 2, i+offset)\n",
    "        plt.imshow(seed_truth[i][:, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(ds, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'seg-shapes.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        #frame = 2*(i**0.5)\n",
    "        #if round(frame) > round(last):\n",
    "        #  last = frame\n",
    "        #else:\n",
    "        #  continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "#if IPython.version_info > (6,2,0,''):\n",
    "display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
