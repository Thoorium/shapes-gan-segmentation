{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import random\n",
    "\n",
    "from IPython import display\n",
    "from skimage.draw import random_shapes, rectangle, polygon, circle\n",
    "\n",
    "tf.config.gpu.set_per_process_memory_growth(enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_SIZE = 128\n",
    "CHANNELS = 3\n",
    "IMAGE_COUNT_STAGE_ONE = 300\n",
    "IMAGE_COUNT_STAGE_TWO = 600\n",
    "NUM_CLASSES = 1 + 2 # BG + Classes\n",
    "MAX_SHAPES = 3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_STAGE_ONE = 75\n",
    "EPOCHS_STAGE_TWO = 75\n",
    "NUM_EXAMPLES_TO_GENERATE = 8\n",
    "USE_FASTSCNN = False\n",
    "COLOR_TRIANGLE = 33\n",
    "COLOR_RECTANGLE = 66\n",
    "COLOR_CIRCLE = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_mask(size=(448, 448), max_shapes=3, show_result=False):\n",
    "    masks = []\n",
    "    triangles = []\n",
    "    rectangles = []\n",
    "    while(len(masks) == 0):\n",
    "        image, labels = random_shapes(size, min_shapes=1, max_shapes=max_shapes,\n",
    "                                 min_size=size[0]/4, allow_overlap=False, multichannel=(CHANNELS == 3),\n",
    "                                     num_trials = 10)#, shape='triangle'\n",
    "        images = []\n",
    "        # Generate individual masks    \n",
    "        for i in range(0, len(labels)):\n",
    "            msk= np.zeros(size, dtype=np.uint8)\n",
    "            img= np.zeros(size, dtype=np.uint8)\n",
    "\n",
    "            if(labels[i][0] == 'rectangle'):\n",
    "                rr, cc = rectangle((labels[i][1][0][0], labels[i][1][1][0]), (labels[i][1][0][1], labels[i][1][1][1]),\n",
    "                           shape=msk.shape)\n",
    "                img[rr, cc] = COLOR_RECTANGLE\n",
    "                images.append(img)\n",
    "                msk[rr, cc] = 1\n",
    "                rectangles.append(msk)\n",
    "                masks.append(msk)\n",
    "            if(labels[i][0] == 'circle'):\n",
    "                y = labels[i][1][0][1]- (labels[i][1][0][1] - labels[i][1][0][0]) / 2\n",
    "                x = labels[i][1][1][1]-(labels[i][1][1][1] - labels[i][1][1][0]) / 2\n",
    "                r = (labels[i][1][0][1] - labels[i][1][0][0]) / 2        \n",
    "                rr, cc = circle(y, x, r, shape=msk.shape)\n",
    "                \n",
    "                img[rr, cc] = COLOR_CIRCLE\n",
    "                images.append(img)\n",
    "            if(labels[i][0] == 'triangle'):\n",
    "                x = (labels[i][1][1][0], labels[i][1][1][1] - (labels[i][1][1][1] - labels[i][1][1][0]) / 2, labels[i][1][1][1], labels[i][1][1][0])\n",
    "                y = (labels[i][1][0][1], labels[i][1][0][0], labels[i][1][0][1], labels[i][1][0][1])\n",
    "                rr, cc = polygon(y, x, shape=msk.shape) \n",
    "                img[rr, cc] = COLOR_TRIANGLE\n",
    "                images.append(img)\n",
    "                msk[rr, cc] = 1\n",
    "                triangles.append(msk)\n",
    "                masks.append(msk)\n",
    "\n",
    "        if(len(masks) == 0):\n",
    "            continue\n",
    "        # Merge the masks\n",
    "        mask = np.zeros(size, dtype=np.uint8)\n",
    "        for i in range(0, len(masks)):\n",
    "            mask = np.add(mask, masks[i])\n",
    "        mask = np.clip(mask,0,1)\n",
    "        background = 1 - mask\n",
    "        \n",
    "        #image = np.zeros(size, dtype=np.uint8)\n",
    "        #for i in range(0, len(images)):\n",
    "        #    image = np.add(image, images[i])\n",
    "        #image = 255 - image\n",
    "        \n",
    "        triangle = np.zeros(size, dtype=np.uint8)\n",
    "        for i in range(0, len(triangles)):\n",
    "            triangle = np.add(triangle, triangles[i])\n",
    "        triangle = np.clip(triangle,0,1)\n",
    "        \n",
    "        mrectangle = np.zeros(size, dtype=np.uint8)\n",
    "        for i in range(0, len(rectangles)):\n",
    "            mrectangle = np.add(mrectangle, rectangles[i])\n",
    "        mrectangle = np.clip(mrectangle,0,1)\n",
    "        \n",
    "        final_mask = np.dstack((background, triangle, mrectangle))\n",
    "\n",
    "        if(show_result):\n",
    "            print(labels)\n",
    "            fig=plt.figure(figsize=(8, 8))\n",
    "            fig.add_subplot(1, len(labels)+1, 1)\n",
    "            plt.imshow(image)\n",
    "            for i in range(0, len(labels)):    \n",
    "                fig.add_subplot(1, len(labels)+1, i+2)\n",
    "                plt.imshow(masks[i], cmap=\"Greys\")\n",
    "            plt.show()\n",
    "        return image, final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(raw_image):\n",
    "    t = tf.convert_to_tensor(raw_image, np.float32)\n",
    "    #print(t.shape)\n",
    "    if(CHANNELS == 1):\n",
    "        t = tf.reshape(t, (SHAPE_SIZE, SHAPE_SIZE, CHANNELS,))\n",
    "    #    t = (t - 127.5) / 127.5\n",
    "    #else: t = t / 255.0\n",
    "    t = t / 255.0\n",
    "    return t\n",
    "\n",
    "def preprocess_mask(raw_mask):\n",
    "    t = tf.convert_to_tensor(raw_mask, np.float32)\n",
    "    t = tf.reshape(t, (SHAPE_SIZE, SHAPE_SIZE, NUM_CLASSES,))\n",
    "    #t = (t - 127.5) / 127.5\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(image_count):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for i in range(0, image_count):\n",
    "        image, img_mask = generate_image_mask(size=(SHAPE_SIZE, SHAPE_SIZE), max_shapes=MAX_SHAPES)\n",
    "        images.append(preprocess_image(image))\n",
    "        masks.append(preprocess_mask(img_mask))\n",
    "        #masks.append(img_mask)\n",
    "        if((i / image_count * 100.0) % 10 == 0):\n",
    "            print(i)\n",
    "    # Display a sample image\n",
    "    print(images[0].shape)\n",
    "    if(CHANNELS == 1):\n",
    "        plt.imshow(images[0][:, :, 0], cmap='gray')\n",
    "    else : plt.imshow(images[0])\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_s1, masks_s1 = generate_dataset(IMAGE_COUNT_STAGE_ONE)\n",
    "img_ds_s1 = tf.data.Dataset.from_tensor_slices(images_s1)\n",
    "msk_ds_s1 = tf.data.Dataset.from_tensor_slices(masks_s1)\n",
    "img_msk_ds_s1 = tf.data.Dataset.zip((img_ds_s1, msk_ds_s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_s2, masks_s2 = generate_dataset(IMAGE_COUNT_STAGE_TWO)\n",
    "img_ds_s2 = tf.data.Dataset.from_tensor_slices(images_s2)\n",
    "msk_ds_s2 = tf.data.Dataset.from_tensor_slices(masks_s2)\n",
    "img_msk_ds_s2 = tf.data.Dataset.zip((img_ds_s2, msk_ds_s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "ds1 = img_msk_ds_s1.shuffle(buffer_size=IMAGE_COUNT_STAGE_ONE)\n",
    "#ds = ds.repeat()\n",
    "ds1 = ds1.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "ds1 = ds1.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "ds2 = img_msk_ds_s2.shuffle(buffer_size=IMAGE_COUNT_STAGE_TWO)\n",
    "#ds = ds.repeat()\n",
    "ds2 = ds2.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "ds2 = ds2.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    c = 32\n",
    "    model = tf.keras.Sequential()\n",
    "    max_depth = SHAPE_SIZE // c\n",
    "    true_depth = 1\n",
    "    print('Max depth:{}'.format(max_depth))\n",
    "    # DOWN    \n",
    "    for i in range(1, max_depth+1):\n",
    "        print(i)\n",
    "        cc = int(c * (i * 2))\n",
    "        model.add(layers.Conv2D(cc, (2, 2), strides=(1, 1), padding='same', use_bias=False, input_shape=(SHAPE_SIZE,SHAPE_SIZE,CHANNELS)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "\n",
    "        model.add(layers.MaxPool2D())\n",
    "        true_depth = true_depth + 1\n",
    "        \n",
    "        # Making sure we don't end up into negative dimensions\n",
    "        if(model.output_shape[1] == 1):\n",
    "            print('True depth:{}'.format(true_depth))\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    # UP    \n",
    "    for i in range(true_depth, 1, -1):\n",
    "        cc = int(c * (i * 2))\n",
    "        model.add(layers.Conv2DTranspose(cc, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "        \n",
    "        if(model.output_shape[1] == SHAPE_SIZE):\n",
    "            break\n",
    "\n",
    "    model.add(layers.Conv2D(NUM_CLASSES, (1, 1), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.Softmax())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_FASTSCNN:\n",
    "    generator = make_generator_model()\n",
    "else:\n",
    "    import fastscnn\n",
    "    generator = fastscnn.build((SHAPE_SIZE, SHAPE_SIZE, CHANNELS))\n",
    "\n",
    "noise = tf.random.normal([1, SHAPE_SIZE, SHAPE_SIZE, CHANNELS])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image.shape)\n",
    "\n",
    "if(CHANNELS == 1):\n",
    "    plt.imshow(generated_image[0, :, :, 1], cmap='gray')\n",
    "else: plt.imshow(generated_image[0, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image2 = generator(tf.reshape(tf.convert_to_tensor(images_s1[0]), (1, SHAPE_SIZE, SHAPE_SIZE, CHANNELS)), training=False)\n",
    "print(generated_image2.shape)\n",
    "if(CHANNELS == 1):\n",
    "    plt.imshow(generated_image2[0, :, :, 1], cmap='gray')\n",
    "else: plt.imshow(generated_image2[0, :, :, 1])\n",
    "#generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[SHAPE_SIZE, SHAPE_SIZE, NUM_CLASSES]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model2():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[SHAPE_SIZE, SHAPE_SIZE, NUM_CLASSES]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    #model.add(layers.Reshape((1,3)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model2()\n",
    "timage = tf.reshape(tf.convert_to_tensor(images_s1[0]), (1, SHAPE_SIZE, SHAPE_SIZE, CHANNELS))\n",
    "tfinal = tf.concat([timage, generated_image], -1)\n",
    "print(tfinal.shape)\n",
    "decision = discriminator(generated_image)\n",
    "print(decision.shape)\n",
    "print (np.unique(decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "    #return cce(real_output, fake_output)\n",
    "\n",
    "def generator_loss(disc_output):\n",
    "    return cross_entropy(tf.ones_like(disc_output), disc_output)\n",
    "    \n",
    "def mask_loss(truth, gen_output):\n",
    "    return cce(truth, gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = SHAPE_SIZE\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "#seed = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, noise_dim, noise_dim, 1])\n",
    "seed = []\n",
    "seed_truth = []\n",
    "for i in range(0, NUM_EXAMPLES_TO_GENERATE):\n",
    "    img, truth = generate_image_mask(size=(SHAPE_SIZE, SHAPE_SIZE), max_shapes=MAX_SHAPES)\n",
    "    seed.append(preprocess_image(img))\n",
    "    seed_truth.append(preprocess_mask(truth))\n",
    "seed = tf.convert_to_tensor(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images, masks, stage):\n",
    "    #noise = tf.random.normal([BATCH_SIZE, noise_dim, noise_dim, 1])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(images, training=True)\n",
    "\n",
    "        #real_output = discriminator(tf.concat([images, masks], -1), training=True)\n",
    "        #fake_output = discriminator(tf.concat([images, generated_images], -1), training=True)\n",
    "        real_output = discriminator(masks, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        if stage == '1':\n",
    "            gen_loss = mask_loss(masks, generated_images)\n",
    "        else:\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, stage):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch, mask_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch, mask_batch, stage)\n",
    "\n",
    "        # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator,\n",
    "                                 epoch + 1,\n",
    "                                 stage,\n",
    "                                 seed)\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix + \"_\" + stage)\n",
    "\n",
    "        print('Stage: {}'.format(stage))\n",
    "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "        print('Generator loss is {}'.format(gen_loss))\n",
    "        print('Discriminator loss is {}'.format(disc_loss))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           stage,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, stage, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(NUM_EXAMPLES_TO_GENERATE,NUM_EXAMPLES_TO_GENERATE))\n",
    "    columns = 3 + NUM_CLASSES\n",
    "    offset = 1\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, columns, i+offset)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, columns, i+offset)\n",
    "        plt.imshow(predictions[i, :, :, 1], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, columns, i+offset)\n",
    "        plt.imshow(predictions[i, :, :, 2], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, columns, i+offset)\n",
    "        plt.imshow(seed_truth[i][:, :, 1], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, columns, i+offset)\n",
    "        plt.imshow(seed_truth[i][:, :, 2], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, columns, i+offset)\n",
    "        if(CHANNELS == 1):\n",
    "            plt.imshow(seed[i][:, :, 0], cmap='gray')\n",
    "        else: plt.imshow(seed[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_s{}_{:04d}.png'.format(stage, epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train(ds1, EPOCHS_STAGE_ONE, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(ds2, EPOCHS_STAGE_TWO, '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'seg-shapes.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        #frame = 2*(i**0.5)\n",
    "        #if round(frame) > round(last):\n",
    "        #  last = frame\n",
    "        #else:«\n",
    "        #  continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "#if IPython.version_info > (6,2,0,''):\n",
    "display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
